% Kaskad Korelasyon (CCNN)
clear;
clc;
close all;
rng(0);

%% 1. VERİ SETİNİ YÜKLEME VE HAZIRLAMA
load twotankdata;
z1f_full = iddata(y, u, 0.2, 'Name', 'Two-tank system');
z1 = z1f_full(1:1500);
z1f = idfilt(z1, 3, 0.066902);
z1f = z1f(20:end);

u_data = z1f.u;
t_data = z1f.y;

% --- NORMALİZASYON EKLENİYOR ---
% Giriş ve çıkış verilerini normalize et
u_mean = mean(u_data);
u_std = std(u_data);
t_mean = mean(t_data);
t_std = std(t_data);

u_data_normalized = (u_data - u_mean) / u_std;
t_data_normalized = (t_data - t_mean) / t_std;

% Normalize edilmiş verileri kullan
u_data = u_data_normalized;
t_data = t_data_normalized;

L = length(u_data);
% Girişler: u(k-1), u(k-2), y(k-1), y(k-2)
% Hedef: y(k)
% Veri mecburen 3. adımdan başlayacak (çünkü k-2'ye ihtiyacımız var)

% X Regresörleri: [u(k-1), u(k-2), y(k-1), y(k-2)]
% u(k-1) -> 2'den L-1'e kadar
% u(k-2) -> 1'den L-2'ye kadar
X_regressors = [u_data(2:L-1), u_data(1:L-2), t_data(2:L-1), t_data(1:L-2)];

% Hedefler: y(k) -> 3'ten L'ye kadar
T_targets = t_data(3:L);

X_RegressorsWithBias = [ones(size(X_regressors, 1), 1), X_regressors];
[N, num_inputs] = size(X_RegressorsWithBias);
num_outputs = 1;

disp('Veri seti yüklendi. Yapı: 2. Dereceden (Lag=2)');

%% 2. HİPERPARAMETRELER VE YARDIMCI FONKSİYONLAR

% --- ÇIKIŞ AĞIRLIKLARI İÇİN EĞİTİM YÖNTEMİ SEÇİMİ ---
% Seçenekler:
%   'Quickprop_DL'  -> trainOutputLayer_Quickprop_With_dlgrad.m (Gradyan descenti Matlab'ın kendi fonksiyonu ile kullanır.)
%   'GD_Autograd'   -> trainOutputLayer_GD_Autograd.m (Gradyan descenti Matlab'ın kendi fonksiyonu ile kullanır.)
%   'GD_Fullbatch'  -> trainOutputLayer_GD_fullbatch.m (Gradyan descenti kendi yazdığımız kod ile kullanır.)
%   'GD_MiniBatch'  -> trainOutputLayer_GD.m (Gradyan descenti kendi yazdığımız kod ile kullanır.)
%   'Quickprop_Org' -> trainOutputLayer.m (Quickprop)

config.output_trainer = 'Quickprop_Org'; % <-- DENEME YAPMAK İÇİN SADECE BURAYI DEĞİŞTİRİN

fprintf('*** Seçilen Çıkış Eğitim Yöntemi: %s ***\n', config.output_trainer);

eta_output = 0.001;
mu = 1.75;
max_epochs_output = 300;
min_mse_change = 1e-7;
epsilon = 1e-8;
% Gradient Ascent (Aday Katman) Parametreleri
eta_candidate = 0.00005;
max_epochs_candidate = 1000;
% Aktivasyon Fonksiyonları
g = @(a) tanh(a);
g_prime = @(v) 1 - v.^2;
% --- DİNAMİK BÜYÜME PARAMETRELERİ ---
target_mse = 0.00005; % Hedeflenen MSE
max_hidden_units = 100; 
num_hidden_units = 0; 

%%%%%GRADİAN PARAMETRE
eta_output_gd = 0.005; 
batch_size = 32;

mse_history = [];
%% AŞAMA 1: BAŞLANGIÇ AĞI EĞİTİMİ (Quickprop ile)
fprintf('Aşama 1: Başlangıç ağı (w_o) Quickprop ile eğitiliyor...\n');

w_o_initial = randn(num_inputs, num_outputs)*0.01; % Ham başlangıç

% --- GİRİŞ MATRİSLERİNİ BAŞLATMA ---
X_output_input = X_RegressorsWithBias; % Çıkış katmanının (w_o) gördüğü
X_candidate_input = X_RegressorsWithBias; % Aday birimlerin (w_c) gördüğü

fprintf('Aşama 1: Başlangıç ağı (w_o) "%s" ile eğitiliyor...\n', config.output_trainer);
% Aşama 1:
% Tüm parametreleri tek bir yapıya toplayın
all_params.eta_output = eta_output;
all_params.mu = mu;
all_params.epsilon = epsilon;
all_params.eta_output_gd = eta_output_gd;
all_params.batch_size = batch_size;

[w_o_stage1_trained, E_residual, current_mse] = runOutputTraining(...
    config.output_trainer, ...
    X_output_input, ...
    T_targets, ...
    w_o_initial, ...
    max_epochs_output, ...
    all_params); % Tüm hiperparametreler



T_variance_sum = sum((T_targets - mean(T_targets)).^2);

% DÜZELTME: Tahmin ve hata, EĞİTİLMİŞ w_o_stage1_trained ile hesaplanır
Y_pred_stage1 = X_output_input * w_o_stage1_trained;
% E_residual ve current_mse zaten fonksiyondan geldi.
% Sadece FİT yüzdesini hesaplamamız gerekiyor:
fit_percentage_train_stage1 = (1 - (sum(E_residual.^2) / T_variance_sum)) * 100;
                                    
fprintf('Aşama 1 (Gizli Katmansız) MSE: %f\n', current_mse);
fprintf('Aşama 1 (Gizli Katmansız) EĞİTİM Fit Yüzdesi: %.2f%%\n', fit_percentage_train_stage1);
mse_history(1) = current_mse; % İlk (0 gizli birim) MSE'sini kaydet
%% AŞAMA 2: DİNAMİK BİRİM EKLEME DÖNGÜSÜ
W_hidden = {}; % Dondurulmuş aday birim ağırlıklarını saklamak için

% DÜZELTME (Hata 5): w_o_trained, döngüde güncellenecek olan son ağırlıktır
% Başlangıç değeri, Aşama 1'de eğittiğimiz değerdir.
w_o_trained = w_o_stage1_trained;

fprintf('\n--- GİZLİ BİRİM EKLEME DÖNGÜSÜ BAŞLATILDI ---\n');

while current_mse > target_mse && num_hidden_units < max_hidden_units
    num_hidden_units = num_hidden_units + 1;
    fprintf('\n--- Gizli Birim #%d Ekleniyor ---\n', num_hidden_units);
    
    % --- AŞAMA 2.a: ADAY BİRİM EĞİTİMİ ---
    [w_new_hidden, v_new_hidden] = ...
        trainCandidateUnit(X_candidate_input, E_residual, ...
                           max_epochs_candidate, eta_candidate, g, g_prime);
    
    % Ağırlıkları ileride kullanmak için sakla (Hata 4 için kontrol)
    W_hidden{num_hidden_units} = w_new_hidden;
    
    % --- AŞAMA 2.b: ÇIKTI KATMANINI YENİDEN EĞİTME ---
    fprintf('Aşama 2.b: Çıktı katmanı (w_o) yeniden eğitiliyor...\n');
    
    % GİRDİ MATRİSLERİNİ GÜNCELLE:
    X_output_input = [X_output_input, v_new_hidden];
    X_candidate_input = [X_candidate_input, v_new_hidden];
    
    % Strateji: Ağırlıkları sıfırdan eğit (Sizin "daha basit" dediğiniz yöntem)
    [~, num_output_inputs_new] = size(X_output_input);
    %w_o_initial_new = randn(num_output_inputs_new, num_outputs) * 0.01;
    w_o_initial_new = [w_o_trained;  % ESKİ, EĞİTİLMİŞ AĞIRLIKLARI KORU
                       randn(1, num_outputs) * 0.01];
    
% --- DÜZELTME (Hata 2) ---
    % Çıkış katmanını GÜNCELLENMİŞ GİRDİLERLE ve seçilen metotla yeniden eğit
    
% Aşama 2.b:
[w_o_trained, E_residual, current_mse] = runOutputTraining(...
    config.output_trainer, ...
    X_output_input, ...
    T_targets, ...
    w_o_initial_new, ... % Yeni başlangıç ağırlığı
    max_epochs_output, ...
    all_params); % Tüm hiperparametreler

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    current_fit = (1 - (sum(E_residual.^2) / T_variance_sum)) * 100;
    mse_improvement = mse_history(end) - current_mse;
        min_mse_improvement = 1e-6; % Durma eşiği

        % Kalan MSE'yi tarihe kaydet (artık doğru sırada)
        mse_history(num_hidden_units + 1) = current_mse;
        
        % Durma Kriteri Kontrolü
        if mse_improvement < min_mse_improvement
            fprintf('Gizli Birim #%d eklendi. YENİ FİT: %.2f%%\n', num_hidden_units, current_fit);
            fprintf('*** MSE iyileşmesi durma eşiği (%.2e) altında kaldı. Döngü sonlandırılıyor. ***\n', min_mse_improvement);
            break; % While döngüsünden çık
        end
        else
            % İlk (0. birim) MSE'sini buraya kaydediyoruz
            % NOT: İlk MSE zaten döngü öncesinde kaydedildiği için bu blok gereksiz olabilir. 
            % Ancak yapıyı korumak için, yine de son MSE'yi döngü sonunda kaydetmeliyiz.
            mse_history(num_hidden_units + 1) = current_mse;
        end
    % --- DÜZELTME BAŞLANGIÇ ---
    if num_hidden_units > 0 % Sadece en az 1 birim eklendiyse (yani döngü 2. kez çalışıyorsa) bu kontrolü yap
        
        % current_mse'yi mse_history'ye kaydetmeden önce iyileşmeyi hesapla
        mse_improvement = mse_history(end) - current_mse;
        min_mse_improvement = 1e-6; % Durma eşiği

        % Kalan MSE'yi tarihe kaydet (artık doğru sırada)
        mse_history(num_hidden_units + 1) = current_mse;
        
        % Durma Kriteri Kontrolü
        if mse_improvement < min_mse_improvement
            fprintf('Gizli Birim #%d eklendi. YENİ FİT: %.2f%%\n', num_hidden_units, current_fit);
            fprintf('*** MSE iyileşmesi durma eşiği (%.2e) altında kaldı. Döngü sonlandırılıyor. ***\n', min_mse_improvement);
            break; % While döngüsünden çık
        end
    else
        % İlk (0. birim) MSE'sini buraya kaydediyoruz
        % NOT: İlk MSE zaten döngü öncesinde kaydedildiği için bu blok gereksiz olabilir. 
        % Ancak yapıyı korumak için, yine de son MSE'yi döngü sonunda kaydetmeliyiz.
        mse_history(num_hidden_units + 1) = current_mse;
    end
    % --- DÜZELTME BİTİŞ ---
        
    % Yazdırma (fprintf) satırını güncelle
    fprintf('Gizli Birim #%d eklendi. Yeni MSE: %f | YENİ FİT: %.2f%%\n', ...
            num_hidden_units, current_mse, current_fit);
    
end
fprintf('--- Gizli Birim Ekleme Döngüsü Tamamlandı. Toplam %d birim eklendi ---\n', num_hidden_units);
%% 3. EĞİTİM SONUÇLARINI GÖRSELLEŞTİRME
[Y_pred_final, fit_percentage_train_final] = plotTrainingResults(...
    T_targets, ...
    Y_pred_stage1, ...
    fit_percentage_train_stage1, ...
    X_output_input, ...
    w_o_trained, ...
    num_hidden_units);

% --- NORMALİZE TAHMİNLERİ ORİJİNAL ÖLÇEĞE ÇEVİR ---
T_targets_original = denormalize_output(T_targets, t_mean, t_std);
Y_pred_stage1_original = denormalize_output(Y_pred_stage1, t_mean, t_std);
Y_pred_final_original = denormalize_output(Y_pred_final, t_mean, t_std);

% Orijinal ölçekte fit yüzdesini hesapla
fit_percentage_train_stage1_original = (1 - (sum((T_targets_original - Y_pred_stage1_original).^2) / ...
                                       sum((T_targets_original - mean(T_targets_original)).^2))) * 100;
fit_percentage_train_final_original = (1 - (sum((T_targets_original - Y_pred_final_original).^2) / ...
                                     sum((T_targets_original - mean(T_targets_original)).^2))) * 100;

fprintf('ORİJİNAL ÖLÇEK - Aşama 1 Fit: %.2f%%, Final Fit: %.2f%%\n', ...
        fit_percentage_train_stage1_original, fit_percentage_train_final_original);

%% 4. ADIM: DOĞRULAMA (VALIDATION) İLE PERFORMANS TESTİ
[fit_val, fit_val_stage1] = evaluateModel_1(...
    z1f_full, ...
    1501:3000, ...
    w_o_stage1_trained, ...
    w_o_trained, ...
    W_hidden, ...
    g, ...
    'CCNN DOĞRULAMA Performansı', ...
    u_mean, u_std, t_mean, t_std); % Normalizasyon parametrelerini ekle
%% 6. ADIM: KAYIP (LOSS) GELİŞİM GRAFİĞİ
plotLossHistory(mse_history, target_mse);
%% 7. ADIM: SİMÜLASYON MODU (Recursive Prediction / Free Run)
fprintf('\n--- Simülasyon (Free Run) Modu Başlatılıyor ---\n');

val_indices = 1501:3000; 
data_val = z1f_full(val_indices);
u_val_raw = data_val.u;
y_val_raw = data_val.y;

z2 = z1f_full(val_indices);
z2f = idfilt(z2, 3, 0.066902);
u_val = z2f.u;
y_val = z2f.y;

% --- DOĞRULAMA VERİSİNİ DE NORMALİZE ET ---
u_val_normalized = (u_val - u_mean) / u_std;
y_val_normalized = (y_val - t_mean) / t_std;

% Normalize edilmiş verilerle simülasyon yap
[y_simulation_normalized, fit_simulation] = simulateCCNNModel(...
    u_val_normalized, ...
    y_val_normalized, ...
    w_o_trained, ...
    W_hidden, ...
    g);

% Simülasyon çıktısını orijinal ölçeğe çevir
y_simulation_original = denormalize_output(y_simulation_normalized, t_mean, t_std);

% Orijinal ölçekte fit hesapla
fit_simulation_original = (1 - (norm(y_val - y_simulation_original) / norm(y_val - mean(y_val)))) * 100;

fprintf('Simülasyon (Normalize) Fit Yüzdesi: %.2f%%\n', fit_simulation);
fprintf('Simülasyon (Orijinal) Fit Yüzdesi: %.2f%%\n', fit_simulation_original);

%% 8. ADIM: BASİT SİMÜLASYON GRAFİĞİ
time_axis = (1:length(y_val))'; % Örnek numaraları
figure('Name', 'CCNN Simülasyon Sonuçları', 'Color', 'w');
plot(time_axis, y_val, 'k-', 'LineWidth', 2, 'DisplayName', 'Gerçek Değerler');
hold on;
plot(time_axis, y_simulation_original, 'r--', 'LineWidth', 1.5, 'DisplayName', sprintf('Simülasyon (Fit: %.2f%%)', fit_simulation_original));
hold off;
title('CCNN Simülasyon: Gerçek vs Tahmin Edilen Çıkışlar');
xlabel('Zaman (saniye)');
ylabel('Su Seviyesi');
legend('Location', 'best');
grid on;



function [y_sim, fit_sim] = simulateCCNNModel(u_val, y_real_val, w_o, W_hidden, g_func)
    % 2. DERECEDEN SİMÜLASYON (u(k-1), u(k-2), y(k-1), y(k-2))
    
    N = length(u_val);
    y_sim = zeros(N, 1);
    
    % Başlangıç koşulları: İlk 2 adımı gerçek veriden alıyoruz
    % Çünkü k=2 iken k-2 (yani 0. an) elimizde yok.
    y_sim(1) = y_real_val(1); 
    y_sim(2) = y_real_val(2);
    
    num_hidden = length(W_hidden);
    
    % Döngü 3'ten başlıyor (k-2'ye erişmek için)
    for k = 3:N
        % 1. Regresörleri Oluştur
        % Yapı: [Bias, u(k-1), u(k-2), y_sim(k-1), y_sim(k-2)]
        
        u_prev1 = u_val(k-1);
        u_prev2 = u_val(k-2);
        
        y_prev1 = y_sim(k-1); % Kendi tahminimiz (Feedback)
        y_prev2 = y_sim(k-2); % Kendi tahminimiz (Feedback)
        
        current_input = [1, u_prev1, u_prev2, y_prev1, y_prev2];
        
        % 2. Kaskad (Gizli) Katmanlar
        for h = 1:num_hidden
            w_h = W_hidden{h};
            net_h = current_input * w_h;
            v_h = g_func(net_h);
            current_input = [current_input, v_h];
        end
        
        % 3. Çıkış
        y_sim(k) = current_input * w_o;
    end
    
    % Fit Hesabı
    % NRMSE Fit formülü
    fit_sim = (1 - (norm(y_real_val - y_sim) / norm(y_real_val - mean(y_real_val)))) * 100;
end

%% DENORMALİZASYON FONKSİYONLARI
function y_original = denormalize_output(y_normalized, t_mean, t_std)
    y_original = y_normalized * t_std + t_mean;
end

function u_original = denormalize_input(u_normalized, u_mean, u_std)
    u_original = u_normalized * u_std + u_mean;
end